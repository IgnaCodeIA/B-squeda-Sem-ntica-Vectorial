{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6tfCay9SURW"
   },
   "source": [
    "# Word2Vec con Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6yrJAHISZ4r"
   },
   "source": [
    "## Instalación de librerías y carga de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gSKi2-d-4dGG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (2.17.1)\n",
      "Requirement already satisfied: filelock in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ignaciocarrenoromero/anaconda3/envs/Pytorch_DL/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jip7NEukg99Q"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import re\n",
    "from gensim.parsing.preprocessing import strip_punctuation, strip_numeric, strip_short, stem_text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zPrihz2VEHz"
   },
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_corpus = load_dataset(\"large_spanish_corpus\", \"ParaCrawl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elegimos de train el primer millón de ejemplos\n",
    "subset = dataset_corpus['train'].select(range(1000000))\n",
    "subset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QPIHz92R2Ql"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbtKlKd1UmF_"
   },
   "source": [
    "## Procesamiento de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpOhY7jyRATr"
   },
   "outputs": [],
   "source": [
    "def clean_text(batch_sentences):\n",
    "    # extrae el texto de la entrada\n",
    "    text_list = batch_sentences['text']\n",
    "    cleaned_text_list = []\n",
    "    for text in text_list:\n",
    "        # Convierte el texto a minúsculas\n",
    "        text = text.lower()\n",
    "\n",
    "        # Elimina URLs\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "        # Elimina las menciones @ y '#' de las redes sociales\n",
    "        text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "\n",
    "        # Elimina los caracteres de puntuación\n",
    "        text = strip_punctuation(text)\n",
    "\n",
    "        # Elimina los números\n",
    "        text = strip_numeric(text)\n",
    "\n",
    "        # Elimina las palabras cortas\n",
    "        text = strip_short(text, minsize=2)\n",
    "\n",
    "        # Elimina las palabras comunes (stop words)\n",
    "        stop_words = set(stopwords.words('spanish'))\n",
    "        \n",
    "        # Tokeniza el texto por cada oración\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # elimina los stopwords (palabras comunes)\n",
    "        \n",
    "        filtered_text_st =[word for word in tokens if word not in stop_words]\n",
    "        \n",
    "        cleaned_text_list.append(filtered_text_st)\n",
    "\n",
    "\n",
    "\n",
    "    # Devuelve el texto limpio\n",
    "    return {\n",
    "        'text' : cleaned_text_list\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7hRWeSrZ59p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000000/1000000 [01:57<00:00, 8481.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_corpus = subset.map(clean_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xC_1SRrnYJWv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lavado',\n",
       "  'cerebro',\n",
       "  'través',\n",
       "  'medios',\n",
       "  'comunicación',\n",
       "  'amenaza',\n",
       "  'fuerza',\n",
       "  'través',\n",
       "  'militares'],\n",
       " ['constante',\n",
       "  'aluvión',\n",
       "  'doble',\n",
       "  'cañón',\n",
       "  'requiriendo',\n",
       "  'complicidad',\n",
       "  'seres',\n",
       "  'humanos',\n",
       "  'reprimir',\n",
       "  'engañar',\n",
       "  'semejantes',\n",
       "  'tan',\n",
       "  'cacareada',\n",
       "  'magia',\n",
       "  'rápidamente',\n",
       "  'desvanecería',\n",
       "  'disiparía'],\n",
       " ['realidad',\n",
       "  'nuevo',\n",
       "  'om',\n",
       "  'sólo',\n",
       "  'puede',\n",
       "  'mantener',\n",
       "  'ilusión',\n",
       "  'supremacía',\n",
       "  'mágica',\n",
       "  'siempre',\n",
       "  'reprima',\n",
       "  'desvíe',\n",
       "  'potencial',\n",
       "  'humano',\n",
       "  'mora',\n",
       "  'verdadera',\n",
       "  'magia',\n",
       "  'decir',\n",
       "  'capacidad',\n",
       "  'innata',\n",
       "  'especie',\n",
       "  'magia',\n",
       "  'interactiva',\n",
       "  'poderes',\n",
       "  'animación',\n",
       "  'diosa',\n",
       "  'planetaria']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_corpus['text'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4J-HBL-FVxKc"
   },
   "source": [
    "## Carga y uso de modelo de embeddings Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7E121yKbljm"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentence_corpus['text'], vector_size=100, window=5, min_count=2, workers=4, sg=1)\n",
    "\n",
    "# Podemos guardar el modelo para uso futuro\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-Qho2ckg0xd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01775959,  0.06014758,  1.1201856 ,  0.85155106,  0.04822263,\n",
       "       -0.21653563,  0.29199094,  0.64293474, -0.18336612,  0.09501904,\n",
       "       -0.8040728 , -0.52166975,  0.3661424 ,  0.24856174, -0.6375646 ,\n",
       "       -0.22724645,  0.33896494, -0.918988  ,  0.48282984,  0.5330522 ,\n",
       "       -0.14381169,  0.8380222 ,  0.42422083,  0.06555478,  0.70205855,\n",
       "       -0.19463238, -0.05770623,  0.07866146, -0.3106073 ,  0.008195  ,\n",
       "       -0.5552841 ,  0.46386743,  0.07576317, -0.5845578 , -0.57834846,\n",
       "        0.4358849 , -0.36418912, -0.41799632, -0.2569206 , -0.6127153 ,\n",
       "       -0.2619601 , -0.05185571, -0.34142482,  0.09443165, -0.07691523,\n",
       "        0.21536507, -0.8239192 , -0.04915377, -0.03385297,  0.1636164 ,\n",
       "        0.6041658 , -0.6106307 ,  0.01406347,  0.09174182, -0.47830933,\n",
       "       -0.21365976, -0.05881346, -0.46212432,  0.04515149,  0.4269978 ,\n",
       "       -0.0901477 ,  0.0605472 ,  0.13558947, -0.49378043,  0.06787198,\n",
       "        0.8284292 , -0.33021188,  0.46007028, -0.570047  ,  0.01403649,\n",
       "       -0.3127246 ,  0.41253772,  0.4219107 ,  0.40345505,  0.6517581 ,\n",
       "        0.31285203, -0.4576283 , -0.93468666, -0.31947693,  0.0190237 ,\n",
       "        0.17777893, -0.6287627 , -0.69290346,  0.09190977,  0.41747507,\n",
       "        0.6383737 ,  0.20402022, -0.08922233, -0.04555546,  0.31083775,\n",
       "        0.1293946 , -0.05284481, -0.40913904, -0.01848396,  0.76609135,\n",
       "        0.45933053,  0.3136064 , -0.26136914,  0.41489518, -0.1405756 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probamos la representación vectorial de una palabra\n",
    "model.wv['rey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1ssleSObsUc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('comer', 0.7584296464920044),\n",
       " ('comidas', 0.7391618490219116),\n",
       " ('sabrosa', 0.7338200211524963)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# con vw.most_similar podemos encontrar las palabras más similares a una dada\n",
    "model.wv.most_similar('comida',topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytaIZOJHiUrj"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_y9DpAyLWCVN"
   },
   "source": [
    "## similitud de palabras y preparacion para visualizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYeA70cVnQ_J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sofía', 0.7716379165649414),\n",
       " ('peinador', 0.735051155090332),\n",
       " ('semíramis', 0.7190153002738953)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('reina',topn=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tiIoHVLn85G"
   },
   "outputs": [],
   "source": [
    "# separar los vectores y las palabras\n",
    "word_and_vectors = model.wv\n",
    "vectors = model.wv.vectors\n",
    "words = model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128768"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almacenamiento de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsv = pd.DataFrame(vectors)\n",
    "df_tsv.to_csv('vectors.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsv = pd.DataFrame(words)\n",
    "df_tsv.to_csv('words.tsv', sep='\\t', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
